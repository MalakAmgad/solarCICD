name: solar system workflow

on:
  workflow_dispatch:
  push:
    branches: 
      - feature-brancheA
      - main
env: 
   MONGO_URI: "mongodb+srv://supercluster.d83jj.mongodb.net/superData"
   MONGO_USERNAME: ${{ secrets.MONGO_USERNAME }}
   MONGO_PASSWORD: ${{secrets.MONGO_PASSWORD }}


jobs:
  unit-testing:
    name: Unit Testing    
    strategy:
      matrix:
        nodejs_version: [18, 19, 20]   
        os: [ubuntu-latest, macos-latest, windows-latest]
        exclude:
          - nodejs_version: 18
            os: macos-latest
    runs-on: ${{ matrix.os }}

    steps: 
      - name: Checkout Repo
        uses: actions/checkout@v5
      
      - name: Setup NodeJs version - ${{ matrix.nodejs_version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.nodejs_version }}

      - name: Install dep
        run: npm install

      - name: Unit testing
        run: npm test
        id: unit-testing-step  
      
      - name: Archive test result
        if: steps.unit-testing-step.outcome == 'failure' || steps.unit-testing-step.outcome == 'success'
        uses: actions/upload-artifact@v4
        with:
          name: SP-Test-Results-${{matrix.nodejs_version}}-${{matrix.os}}
          path: test-results.xml

  code-coverage:
    name: Code Coverage
    needs: unit-testing
    runs-on: ubuntu-latest
    steps:
        - name: Checkout Repo
          uses: actions/checkout@v2

        - name: Setup Node.js version - 18
          uses: actions/setup-node@v4
          with:
            node-version: 18
        - name: Install dependencies
          run: npm install
        
        - name: Check code coverage
          continue-on-error: true
          run: npm run coverage
        
        - name: Archive coverage results
          uses: actions/upload-artifact@v4
          with:
            name: code-coverage-results
            path: coverage
            retention-days: 5
  
  docker:
      name: containerization
      needs: [code-coverage, unit-testing]
      permissions:
        packages: write
        contents: read
      runs-on: ubuntu-latest
      steps:
        - name: Checkout Repo
          uses: actions/checkout@v5
    
        - name: docker login
          uses: docker/login-action@v2.2.0
          with:
            username: ${{ secrets.DOCKER_HUB_USERNAME }}
            password: ${{ secrets.DOCKER_HUB_TOKEN }}

        - name: GCHR login
          uses: docker/login-action@v2.2.0
          with:
            registry: ghcr.io
            username: ${{ github.actor }}
            password: ${{ secrets.GITHUB_TOKEN }}
    
        - name: Set lowercase repo owner
          id: repo
          run: echo "owner=$(echo '${{ github.repository_owner }}' | tr '[:upper:]' '[:lower:]')" >> $GITHUB_OUTPUT
    
        - name: Build Docker image
          uses: docker/build-push-action@v6
          with:
            push: true
            tags: |
              docker.io/${{ secrets.DOCKER_HUB_USERNAME }}/solar-system:${{ github.sha }}
              docker.io/${{ secrets.DOCKER_HUB_USERNAME }}/solar-system:latest

              ghcr.io/${{ steps.repo.outputs.owner }}/solar-system:${{ github.sha }}
    
    
        - name: Test Docker image
          run: |
            docker images
            docker run --name solar-system-app -d \
            -p 3000:3000 \
            -e MONGO_URI=$MONGO_URI \
            -e MONGO_USERNAME=$MONGO_USERNAME \
            -e MONGO_PASSWORD=$MONGO_PASSWORD \
            ${{ secrets.DOCKER_HUB_USERNAME }}/solar-system:latest
            export IP=$(docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' solar-system-app)
            echo "IP Address: $IP"
    
            echo Testing Image URL using wget
            wget -q -O - 127.0.0.1:3000/live | grep live
  trivy-scan:
    name: Trivy Security Scan
    needs: docker
    runs-on: ubuntu-latest
    permissions:        
     contents: read
     security-events: write  
     actions: read
    steps:
      - name: Checkout Repo
        uses: actions/checkout@v5

      - name: Scan Docker Image
        uses: aquasecurity/trivy-action@0.20.0
        with:
          scan-type: image
          image-ref: ${{ secrets.DOCKER_HUB_USERNAME  }}/solar-system:${{ github.sha }}
          format: table
          output: trivy-image-report.txt
          severity: HIGH,CRITICAL
          ignore-unfixed: true
          exit-code: 0

      - name: Generate SBOM (CycloneDX)
        uses: aquasecurity/trivy-action@0.20.0
        with:
          scan-type: image
          image-ref: ${{ secrets.DOCKER_HUB_USERNAME }}/solar-system:${{ github.sha }}
          format: cyclonedx
          output: trivy-sbom.cdx
          exit-code: 0

      - name: Scan Docker Image (SARIF)
        uses: aquasecurity/trivy-action@0.20.0
        with:
          scan-type: image
          image-ref: ${{ secrets.DOCKER_HUB_USERNAME }}/solar-system:${{ github.sha }}
          format: sarif
          output: trivy-results.sarif
          exit-code: 0
      - name: Upload SARIF results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: trivy-results.sarif

      - name: Scan Terraform configs
        uses: aquasecurity/trivy-action@0.20.0
        with:
          scan-type: config
          scan-ref: ./terraform
          format: table
          output: trivy-terraform-report.txt
          severity: HIGH,CRITICAL
          ignore-unfixed: true
          exit-code: 0

      - name: Scan Source Code for Secrets
        uses: aquasecurity/trivy-action@0.20.0
        with:
          scan-type: fs
          scan-ref: .
          format: table
          output: trivy-secrets-report.txt
          severity: HIGH,CRITICAL
          exit-code: 0

      - name: Upload Trivy Reports
        if: always()
        uses: actions/upload-artifact@v4.6.2
        with:
          name: trivy-reports
          path: |
            trivy-image-report.txt
            trivy-sbom.cdx
            trivy-results.sarif
            trivy-terraform-report.txt
            trivy-secrets-report.txt
            
  terraform:
    name: Terraform Deployment
    needs: [docker, code-coverage, unit-testing, trivy-scan]
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Checkout config files
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4.3.1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: HashiCorp - Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.1.7"

      - name: Terraform Init
        run: terraform init
        working-directory: ./terraform

      #- name: Terraform Destroy (clean environment)
      #  run: terraform destroy -auto-approve  
      - name: Terraform Plan
        run: terraform plan
        working-directory: ./terraform
        
      - name: Terraform Apply
        run: terraform apply -auto-approve
        working-directory: ./terraform

  deploy:
    needs: terraform
    name: Deploy to EkS
    runs-on: ubuntu-latest

    steps:
      - name: Checkout config files
        uses: actions/checkout@v3

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4.3.1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: Update kubeconfig
        run: |
          aws eks --region us-west-2 update-kubeconfig --name stage-eks-cluster

      - name: Trigger app deployment
        uses: statsig-io/kubectl-via-eksctl@main
        env:
           aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
           aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
           region: us-west-2
           cluster: stage-eks-cluster
      - name: Deploy k8s deployments
        run: |
         kubectl apply -f deployment.yml
         kubectl apply -f service.yml
        working-directory: ./kubernetes
      - name: Verify Deployment
        run: |
          kubectl get pods  
          kubectl get svc
      - name: Get LoadBalancer URL
        run: |
          echo "Waiting for LoadBalancer to be provisioned..."
          kubectl wait --for=condition=available deployment/microservice-deployment --timeout=120s || true
          kubectl get svc microservice-service -o jsonpath='{.status.loadBalancer.ingress[0].hostname}'
          
  deploy-monitoring:
    needs: deploy
    name: deploy to EKS (monitoring)
    runs-on: ubuntu-latest
    env:
      AWS_REGION: us-west-2
      EKS_CLUSTER_NAME: stage-eks-cluster
      GRAFANA_ADMIN_PASSWORD: ${{ secrets.grafana_admin_password }}

    steps:
      - name: checkout config files
        uses: actions/checkout@v5

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4.3.1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-2

      - name: updat kubeconfig
        run: |
          aws eks --region us-west-2 update-kubeconfig --name stage-eks-cluster

      - name: Trigger app deployment
        uses: statsig-io/kubectl-via-eksctl@main
        env:
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          region: us-west-2
          cluster: stage-eks-cluster

      - name: create monitoring namespace
        run: kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

      - name: Add Helm repos
        run: |
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo add grafana https://grafana.github.io/helm-charts
          helm repo update

      - name: Render values with env
        run: |
          envsubst < values.yml > /tmp/values.rendered.yaml
          echo "Rendered values:"
          tail -n +1 /tmp/values.rendered.yaml
        working-directory: ./kubernetes

      # ---- NEW: apply chart CRDs first to avoid Helm pre-upgrade CRD/hooks conflicts ----
      - name: Install Prometheus CRDs (pre-install)
        run: |
          echo "Applying kube-prometheus-stack CRDs (so Helm won't hang on CRD hooks)"
          kubectl apply -f https://raw.githubusercontent.com/prometheus-community/helm-charts/main/charts/kube-prometheus-stack/crds/crds.yaml
        working-directory: ./kubernetes

      - name: Install/Upgrade kube-prometheus-stack
        id: helm_install
        run: |
          set -euo pipefail
          helm repo update
          # We explicitly skip CRDs because we applied them above.
          # --atomic + --cleanup-on-fail ensure partial installs are cleaned up on failure.
          helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --values /tmp/values.rendered.yaml \
            --skip-crds --atomic --cleanup-on-fail --wait
        working-directory: ./kubernetes

      - name: Apply ServiceMonitor for my app
        run: |
          kubectl apply -f servicemonitor-splar-system.yaml
        working-directory: ./kubernetes

      - name: Show external endpoints
        run: |
          echo "Waiting for LoadBalancer IPs..."
          kubectl -n monitoring wait --for=condition=available deploy/kube-prometheus-stack-grafana --timeout=10m
          kubectl -n monitoring get svc -o wide
          echo "Grafana URL:"
          kubectl -n monitoring get svc kube-prometheus-stack-grafana -o jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}{.status.loadBalancer.ingress[0].ip}{"\n"}'
          echo "Prometheus URL:"
          kubectl -n monitoring get svc kube-prometheus-stack-prometheus -o jsonpath='{.status.loadBalancer.ingress[0].hostname}{"\n"}{.status.loadBalancer.ingress[0].ip}{"\n"}'

      # ---- Debug diagnostics (runs only on failure) ----
      - name: Monitoring debug dump
        if: ${{ failure() }}
        run: |
          set -e
          mkdir -p /tmp/monitoring-debug
          echo "=== NAMESPACE: monitoring - PODS ===" > /tmp/monitoring-debug/pods.txt
          kubectl -n monitoring get pods -o wide >> /tmp/monitoring-debug/pods.txt || true
          echo "=== EVENTS (last) ===" > /tmp/monitoring-debug/events.txt
          kubectl -n monitoring get events --sort-by='.metadata.creationTimestamp' >> /tmp/monitoring-debug/events.txt || true
          echo "=== LIST PODS NOT READY ===" > /tmp/monitoring-debug/not_ready.txt
          kubectl -n monitoring get pods --field-selector=status.phase!=Running -o jsonpath='{.items[*].metadata.name}' | tr ' ' '\n' >> /tmp/monitoring-debug/not_ready.txt || true
          # Describe up to 5 non-ready pods
          idx=0
          for p in $(kubectl -n monitoring get pods --field-selector=status.phase!=Running -o jsonpath='{.items[*].metadata.name}' | tr ' ' '\n'); do
            if [ $idx -ge 5 ]; then break; fi
            echo "---- POD: $p ----" >> /tmp/monitoring-debug/describe_$idx.txt
            kubectl -n monitoring describe pod $p >> /tmp/monitoring-debug/describe_$idx.txt || true
            kubectl -n monitoring logs $p --all-containers --tail=200 >> /tmp/monitoring-debug/describe_$idx.txt || true
            idx=$((idx+1))
          done
          tar -czf /tmp/monitoring-debug.tar.gz -C /tmp monitoring-debug || true

      - name: Upload monitoring debug artifacts
        if: ${{ failure() }}
        uses: actions/upload-artifact@v4
        with:
          name: monitoring-debug
          path: /tmp/monitoring-debug.tar.gz
                    




                          
            
